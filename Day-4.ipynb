{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58da4584-bb3a-45a4-ac5c-1ff4dc97fa6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dependencies and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7342a027-6c67-4033-9ff2-404109f0474e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the python-Levenshtein package using pip\n",
    "#!pip install python-Levenshtein\n",
    "\n",
    "# Import necessary libraries and modules\n",
    "\n",
    "import Levenshtein  # Library for computing Levenshtein (edit) distance\n",
    "\n",
    "# import numpy and pandas using standard names\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "\n",
    "import re  # Regular expressions module for string operations\n",
    "from tqdm import tqdm  # Module for displaying progress bars\n",
    "\n",
    "# Below we define some functions we will use later.\n",
    "\n",
    "def find_domain_name(x):\n",
    "    \"\"\"\n",
    "    Extracts the domain name from an email address.\n",
    "\n",
    "    Args:\n",
    "        x (str): The input email address.\n",
    "\n",
    "    Returns:\n",
    "        str: The domain name part of the email address.\n",
    "    \"\"\"\n",
    "    # If '@.' return all whole string since this is likely a typo we need to check further.\n",
    "    if \"@.\" in x:\n",
    "        return x\n",
    "    try:\n",
    "        idx = x.index('@')  # Find the index of the '@' symbol\n",
    "        return x[idx+1:]  # Return the substring after the '@' symbol\n",
    "    except:\n",
    "        return x  # If no '@' symbol is found, return the original input\n",
    "\n",
    "def split_and_join(x):\n",
    "    \"\"\"\n",
    "    Removes spaces from a string.\n",
    "\n",
    "    Args:\n",
    "        x (str): The input string.\n",
    "\n",
    "    Returns:\n",
    "        str: The input string with spaces removed.\n",
    "    \"\"\"\n",
    "    return ''.join(x.split())  # Split the string into words, join them without spaces\n",
    "\n",
    "def remove_punctuation(input_string):\n",
    "    \"\"\"\n",
    "    Removes punctuation from a given string.\n",
    "\n",
    "    Args:\n",
    "        input_string (str): The input string containing punctuation.\n",
    "\n",
    "    Returns:\n",
    "        str: The input string with punctuation removed.\n",
    "    \"\"\"\n",
    "    # Define a regular expression pattern to match punctuation\n",
    "    punctuation_pattern = r'[^\\w\\s]'\n",
    "    \n",
    "    # Use re.sub() to replace punctuation with an empty string\n",
    "    clean_string = re.sub(punctuation_pattern, '', input_string)\n",
    "    \n",
    "    return clean_string  # Return the modified string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c029ba1-e014-47df-96e6-43d4860e96c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80643bcf-39c9-4890-a3f7-0c9f7c42ff2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Value_of_Energy_Cost_Savings_Program_Savings_for_Businesses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ce469-aa49-48ce-bd76-3cfde6f22f84",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a7eafd-d5a9-4d6b-b71f-0ba0332ae1d1",
   "metadata": {},
   "source": [
    "Here we will answer the question: How many different companies are represented in the data set? To do this, we need to clean the data since many companies are repeated or misspelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483e5d1c-84ed-4478-9fc7-5aa849296d57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 761/761 [00:00<00:00, 3595.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique companies so far: 762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# First we lowercase the company name and apply the function split_and_join. \n",
    "# split_and_join removes whitespace and concatenates the string.\n",
    "df['Company Name'] = df['Company Name'].str.lower().apply(split_and_join)\n",
    "\n",
    "# We notice on visual inspection that many company names are duplicated, but the \n",
    "# duplicated versions have many duplicated. apostrophes. The code below uses the 're' module \n",
    "# to remove them. That is it replaces the string '''''' with '.\n",
    "df['Company Name'] = df['Company Name'].astype(str).apply(\n",
    "    lambda x:re.sub(\"'+\",\"'\",x))\n",
    "\n",
    "# Next, we remove any punctuation from the company name.\n",
    "df['Company Name'] = df['Company Name'].astype(str).apply(remove_punctuation)\n",
    "\n",
    "# Finally, we remove a common misspelling of \"corporation\".\n",
    "df['Company Name'] = df['Company Name'].astype(str).apply(lambda x: x.replace(\n",
    "    'coporation','corporation'))\n",
    "\n",
    "# The list companies contains the resulting unique set of company names.\n",
    "companies = df['Company Name'].unique()\n",
    "\n",
    "# Next, we test whether the company names are unique by computing the Levenshtein word distance between\n",
    "# the remaining companies. The Levenshtein distance measures how many edits it would take to make two words identical.\n",
    "length = len(companies)\n",
    "\n",
    "# We initialize the \"distance matrix\" so that each element is infinite. This is done out of convenience since we \n",
    "# want to ignore redudant and diagonal matrix elements.\n",
    "dist_matrix = np.full((length,length),float('inf'))\n",
    "\n",
    "# Finally, we measure the word distance between all unique pairs of words.\n",
    "# We restrict to i<j since the word distance metric is symmetric, i.e. the distance between word[i] and word[j]\n",
    "# is the same as the distance between word[j] and word[i]\n",
    "for i in tqdm(range(length-1)):\n",
    "    for j in range(i+1,length):\n",
    "        dist_matrix[i,j] = Levenshtein.distance(companies[i],\n",
    "                                                companies[j])\n",
    "\n",
    "print(f'Total number of unique companies so far: {len(companies)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ca51763-78d6-46e6-8dd4-40bd750cf171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company 162: dlxindustriesinc\n",
      "Company 700: dnjindustriesinc\n",
      "--------------------------------------------------\n",
      "Company 270: jetrocashcarryenterprisesinc\n",
      "Company 647: jetrocashcarryenterprisesllc\n",
      "--------------------------------------------------\n",
      "Company 329: mcndesigninc\n",
      "Company 339: mldesigninc\n",
      "--------------------------------------------------\n",
      "Company 494: tourneauinc\n",
      "Company 757: tourneaullc\n",
      "--------------------------------------------------\n",
      "Company 551: 120wallstreetllc\n",
      "Company 557: 40wallstreetllc\n",
      "--------------------------------------------------\n",
      "Company 581: kickstarterinc\n",
      "Company 649: kickstarterpbc\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Next, let's look at all company names which have a Levenshtein distance <= 2.\n",
    "\n",
    "for i in range(length-1):\n",
    "    for j in range(i+1,length):\n",
    "        if dist_matrix[i,j]<=2:\n",
    "            print(f\"Company {i}: {companies[i]}\")\n",
    "            print(f\"Company {j}: {companies[j]}\")\n",
    "            print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c660cb1-efbe-4d7b-9739-d46bf9461e8c",
   "metadata": {},
   "source": [
    "We notice that the pairs (270,647), (494, 757) and (581,649) are very similar, the only difference is whether the company name inolves \"INC\" or \"LLC\" or \"INC\" vs \"PBC\". A priori, it is not clear to me whether these companies should be considered the same or different. However, given that \"INC\" and \"LLC\" are legally two different terms, I've opted to consider them to be separate companies here. With this assumption, the total number of companies is: len(companies) = 762."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3f309-b4d8-4bae-88de-0ff0319b50f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e14b86-0307-41f2-ba63-c9389eac0873",
   "metadata": {},
   "source": [
    "What is the total number of jobs created for businesses in Queens?\n",
    "\n",
    "To answer this question we will restrict our dataframe df to rows where the borough is Queens, index into the 'Job created' column, and then sum all the entries. This is done in the code below and the final answer is 1196."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bc27da8-34d8-403a-8aa0-d0fe0444e9b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of jobs created in Queens is: 1196.\n"
     ]
    }
   ],
   "source": [
    "num_queens_jobs = df[df['Borough']=='QUEENS']['Job created'].sum()\n",
    "\n",
    "print(f'Total number of jobs created in Queens is: {int(num_queens_jobs)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cdfe56-0c28-46cd-995a-b5505bcab813",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f51b5e8-54c7-411f-af25-5e0046a7f658",
   "metadata": {},
   "source": [
    "How many different unique email domains names are there in the data set?\n",
    "\n",
    "To answer this, we need to extract the contents of the email string after the @ symbol, if it is present. If the @ symbol is not present we will assume the url given is meant to be the domain name. An exception is if the string contains \"@.\" which we assume is a typo. Specifically, the email address 'reinfsupply@.net' in df['company email'] we suspect is a typo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44a6ec33-4f09-4382-8dd4-3cc719d4ef29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique domains found so far: 601.\n"
     ]
    }
   ],
   "source": [
    "# First, we'll standardize the email addresses by lowercasing and removing any potential white space.\n",
    "df['company email'] = df['company email'].str.lower().astype(str).apply(split_and_join)\n",
    "\n",
    "#df['company email'] = df['company email'].str.replace('www.','')\n",
    "df['domains'] = df['company email'].apply(find_domain_name)\n",
    "domains = df['domains'].unique()\n",
    "print(f'Number of unique domains found so far: {len(domains)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64319b7b-3651-47ac-82b5-4bbf6b8b0bd8",
   "metadata": {},
   "source": [
    "As in our solution to question 1, we will use the Levenshtein distance metric to look for common typos in the email address domain names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d249c7ad-83c8-4afd-b878-14fc8835e44e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 600/600 [00:00<00:00, 4630.95it/s]\n"
     ]
    }
   ],
   "source": [
    "domain_length = len(domains)\n",
    "\n",
    "# We again initialize the \"distance matrix\" so that each element is infinite.\n",
    "dist_matrix_domain = np.full((length,length),float('inf'))\n",
    "\n",
    "# Finally, we measure the word distance between all unique pairs of domains.\n",
    "# We again restrict to i<j since the word distance metric is symmetric.\n",
    "\n",
    "for i in tqdm(range(domain_length-1)):\n",
    "    for j in range(i+1,domain_length):\n",
    "        dist_matrix_domain[i,j] = Levenshtein.distance(domains[i],\n",
    "                                                domains[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b5efc1-cc34-45c0-aa2a-af817ffcb637",
   "metadata": {},
   "source": [
    "With emails its more difficult to identify whether something is a typo or not. After all, it is not uncommon for emails to differ by just one letter. For example \"NYU.edu\" and \"YU.edu\" correspond to different institutions, New York University and Yeshiva University. Nevertheless, its still important to check for potential obvious typos in the email addresses.\n",
    "\n",
    "To start, we look for potentially redundant emails by computing the Levenshtein distance between two domain names. Then for each potentially redundant pair, we check to see if the company name agree. If they agree, we add the pair of domain names to the set \"domains_redundant\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34e008bf-92b1-4ce1-a961-1e82b6b6803b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First we collect all domain names which have a Levenshtein distance <= 5.\n",
    "\n",
    "domain_pairs = []\n",
    "\n",
    "for i in range(length-1):\n",
    "    for j in range(i+1,length):\n",
    "        if dist_matrix_domain[i,j]<=5:\n",
    "            domain_pairs.append((domains[i],domains[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f9c5dd0-d72f-466b-b5c6-3b2f286f612c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company 1787: kingsland359llc. Email: ginabws@gmail.com\n",
      "Company 299: kingsland359llc. Email: ebond203@aol.com\n",
      "--------------------------------------------------------------------------------\n",
      "Company 286: josiahmcelhenystudio. Email: markshortliffe@gmail.com\n",
      "Company 1777: josiahmcelhenystudio. Email: josiahmcstudio@yahoo.com\n",
      "--------------------------------------------------------------------------------\n",
      "Company 28: aidsvaccineadvocacycoalition. Email: marie@avac.com\n",
      "Company 605: aidsvaccineadvocacycoalition. Email: marie@avac.org\n",
      "--------------------------------------------------------------------------------\n",
      "Company 72: belmontmetals. Email: jbehrendt@belomtmetals.com\n",
      "Company 1623: belmontmetals. Email: jbehrendt@belmontmetals.com\n",
      "--------------------------------------------------------------------------------\n",
      "Company 188: empressmediainc. Email: dave@empressmedia.com\n",
      "Company 752: empressmediainc. Email: dmiller@empressmam.com\n",
      "--------------------------------------------------------------------------------\n",
      "Company 264: iptnamedesignsinc. Email: jimmy@iptnamedesign.com\n",
      "Company 823: iptnamedesignsinc. Email: jimmy@iptnamedesigns.com\n",
      "--------------------------------------------------------------------------------\n",
      "Company 304: kumoinc. Email: shin@biwaihc.com\n",
      "Company 863: kumoinc. Email: info@kumoinc.com\n",
      "--------------------------------------------------------------------------------\n",
      "Company 418: pintotegerelectric. Email: barryt.teger@pintoandtegerelectrica.com\n",
      "Company 971: pintotegerelectric. Email: barryt.teger@pintoandtegerelectric.com\n",
      "--------------------------------------------------------------------------------\n",
      "Company 446: rolexwatchusainc. Email: mgoldberg@rolexusa.com\n",
      "Company 995: rolexwatchusainc. Email: mgoldberg@rusa.com\n",
      "--------------------------------------------------------------------------------\n",
      "Company 498: thehandytoolmfgcoinc. Email: rochelle@handytool.com\n",
      "Company 1922: thehandytoolmfgcoinc. Email: rochelle@ehandytool.com\n",
      "--------------------------------------------------------------------------------\n",
      "Company 613: allisonedenstudios. Email: garry@allisoneden.comp\n",
      "Company 1599: allisonedenstudios. Email: gary@allisoneden.com\n",
      "--------------------------------------------------------------------------------\n",
      "Company 690: chasebankna. Email: edward.p.rooney@chase.com\n",
      "Company 1654: chasebankna. Email: daniel.g.bambrick@jpmchase.com\n",
      "--------------------------------------------------------------------------------\n",
      "Company 1322: hydromxinc. Email: mikeb@hydromx\n",
      "Company 1754: hydromxinc. Email: mikeb@hydromx.us\n",
      "--------------------------------------------------------------------------------\n",
      "Company 1460: rogerssurveyingpllc. Email: wspiezia@rogerssurveying.com\n",
      "Company 1876: rogerssurveyingpllc. Email: wspiezia@rogerssurveying.net\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Next, for each pair of domain names, we check if the domain names correspond to the same company by \n",
    "# checking whether the company name, phone number, and contact name all agree.\n",
    "\n",
    "import itertools\n",
    "domains_check = set()\n",
    "\n",
    "for domain_pair in domain_pairs:\n",
    "    \n",
    "    domain_1, domain_2 = domain_pair\n",
    "    \n",
    "    company_1 = df[(df['domains']==domain_1)]\n",
    "    company_2 = df[(df['domains']==domain_2)]\n",
    "    \n",
    "    for i,j in itertools.product(company_1.index,company_2.index):\n",
    "        \n",
    "        if (company_1['Company Name'][i]==company_2['Company Name'][j]):\n",
    "\n",
    "                print(f\"Company {i}: {company_1['Company Name'][i]}. Email: {company_1['company email'][i]}\")\n",
    "                print(f\"Company {j}: {company_2['Company Name'][j]}. Email: {company_2['company email'][j]}\")\n",
    "                print('-'*80)\n",
    "                \n",
    "                domains_check.add((domain_1,domain_2))\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce063965-30d9-4513-8506-53cc940f7884",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once again, its not clear what is a typo or not. For example, for the third pair the domains \"avac.com\" and \"avac.org\" may both be valid, or maybe one is a mistake. To be on the conservative side, we will say that only the following are probably typos: \n",
    "\n",
    "1) For the 4th pair, belomtmetals.com is likely a typo since the company name is \"belmontmetals\".\n",
    "2) For the 6th pair, iptnamedesign.com is likely a typo since the company name is \"iptnamedesignsinc\".\n",
    "3) For the 8th pair, pintoandtegerelectrica@.com also looks like a typo since the company name is \"pintotegerelectric\".\n",
    "4) For the 10th pair, handytool.com and ehandytool.com differ by one letter, \"e\", which is also the last letter of \"rochelle\". This may be a typo.\n",
    "5) For the 11th pair, the domain \"allisoneden.comp\" is likely incorrect and it should end with just \".com\".\n",
    "\n",
    "To wrap if, if we just want to count the unique domain names, without looking for typos the final answer is: there are 601 pairs of unique domain names.\n",
    "\n",
    "If we want to count unique domain names, and say that two domain names are the same if they differ by a likely typo, the answer is: there are 601-5 = 596 pairs of unique domain names.\n",
    "\n",
    "My preference is to say there are 596 pairs of unique domain names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6375a10e-233c-48b2-893d-4cc7f2baf9b8",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da5062d-c51b-4bd5-84e5-225178b3534e",
   "metadata": {},
   "source": [
    "Considering only NTAs with at least 5 listed businesses, what is the average total savings and the total jobs created for each NTA?\n",
    "\n",
    "To answer this, we will group the dataframe by the NTA column and filter the grouped dataframe to only retain NTAs with at least 5 businesses.\n",
    "We take the resulting dataframe, group again by the NTA, then index into the \"Total Savings\" and \"Job created\" columns of the resulting dataframe, and finally compute their mean. This is accomplished in the code below. We save the resulting dataframe to the file \"NTA_total_savings_jobs_created.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68a1240c-e03a-45b9-acd2-b33380a7ee3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Savings</th>\n",
       "      <th>Job created</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood Tabulation Area (NTA) (2020)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BK0101</th>\n",
       "      <td>10367.961795</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK0104</th>\n",
       "      <td>21158.253077</td>\n",
       "      <td>10.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK0202</th>\n",
       "      <td>74011.255897</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK0261</th>\n",
       "      <td>12876.958500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK0301</th>\n",
       "      <td>57934.141667</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK0502</th>\n",
       "      <td>13810.223333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK0503</th>\n",
       "      <td>62669.078889</td>\n",
       "      <td>59.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK0601</th>\n",
       "      <td>25358.179524</td>\n",
       "      <td>10.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK0702</th>\n",
       "      <td>17596.188571</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK0802</th>\n",
       "      <td>3620.966591</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK1602</th>\n",
       "      <td>-3744.104444</td>\n",
       "      <td>13.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BX0101</th>\n",
       "      <td>17226.212931</td>\n",
       "      <td>9.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BX0201</th>\n",
       "      <td>21078.529496</td>\n",
       "      <td>7.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BX1001</th>\n",
       "      <td>10510.395882</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN0101</th>\n",
       "      <td>431063.858667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN0102</th>\n",
       "      <td>47655.748000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN0902</th>\n",
       "      <td>2398.261224</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN1102</th>\n",
       "      <td>8909.400625</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0101</th>\n",
       "      <td>14292.983784</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0103</th>\n",
       "      <td>14084.895625</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0104</th>\n",
       "      <td>25843.476364</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0105</th>\n",
       "      <td>59201.958046</td>\n",
       "      <td>11.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0161</th>\n",
       "      <td>2489.384000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0201</th>\n",
       "      <td>27410.526875</td>\n",
       "      <td>11.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0202</th>\n",
       "      <td>13586.924023</td>\n",
       "      <td>13.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0203</th>\n",
       "      <td>6549.470909</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0501</th>\n",
       "      <td>13278.137101</td>\n",
       "      <td>11.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0502</th>\n",
       "      <td>11908.803529</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0701</th>\n",
       "      <td>33604.169773</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN0904</th>\n",
       "      <td>1739.515833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN1306</th>\n",
       "      <td>21160.505200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Total Savings  Job created\n",
       "Neighborhood Tabulation Area (NTA) (2020)                            \n",
       "BK0101                                      10367.961795     5.333333\n",
       "BK0104                                      21158.253077    10.388889\n",
       "BK0202                                      74011.255897          NaN\n",
       "BK0261                                      12876.958500          NaN\n",
       "BK0301                                      57934.141667     4.000000\n",
       "BK0502                                      13810.223333          NaN\n",
       "BK0503                                      62669.078889    59.285714\n",
       "BK0601                                      25358.179524    10.777778\n",
       "BK0702                                      17596.188571     7.666667\n",
       "BK0802                                       3620.966591          NaN\n",
       "BK1602                                      -3744.104444    13.750000\n",
       "BX0101                                      17226.212931     9.636364\n",
       "BX0201                                      21078.529496     7.823529\n",
       "BX1001                                      10510.395882     5.000000\n",
       "MN0101                                     431063.858667          NaN\n",
       "MN0102                                      47655.748000     2.000000\n",
       "MN0902                                       2398.261224     5.000000\n",
       "MN1102                                       8909.400625     4.000000\n",
       "QN0101                                      14292.983784    14.285714\n",
       "QN0103                                      14084.895625     2.000000\n",
       "QN0104                                      25843.476364     7.666667\n",
       "QN0105                                      59201.958046    11.666667\n",
       "QN0161                                       2489.384000          NaN\n",
       "QN0201                                      27410.526875    11.142857\n",
       "QN0202                                      13586.924023    13.888889\n",
       "QN0203                                       6549.470909    10.000000\n",
       "QN0501                                      13278.137101    11.470588\n",
       "QN0502                                      11908.803529     3.000000\n",
       "QN0701                                      33604.169773    10.000000\n",
       "QN0904                                       1739.515833          NaN\n",
       "QN1306                                      21160.505200          NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby('Neighborhood Tabulation Area (NTA) (2020)')\n",
    "grouped = grouped.filter(lambda x:x['Company Name'].nunique()>=5)\n",
    "\n",
    "result = grouped.groupby('Neighborhood Tabulation Area (NTA) (2020)')[['Total Savings','Job created']].mean()\n",
    "\n",
    "result.to_csv(\"NTA_total_savings_jobs_created.csv\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff5f04-1312-44ce-bae5-dbe981b59241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
